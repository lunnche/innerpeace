# 统计学习方法



主要内容：

感知机

k近邻法

朴素贝叶斯法

决策树

逻辑斯谛回归

最大熵模型

支持向量机

提升方法

EM算法

隐马尔科夫模型

条件随机场

聚类方法

奇异值分解

主成分分析

潜在语义分析

概率潜在语义分析

马尔可夫链蒙特卡罗法

潜在狄利克雷分配

PageRank算法





不涉及：

深度学习

强化学习



# 第一章 统计学习及监督学习概论



# 1.1 统计学习

统计学习（statistical learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也称为统计机器学习（statistical machine learning）



学习：如果一个系统能够通过执行某个过程改进它的性能，这就是学习。——赫尔伯特·西蒙（Herbert A. Simon）



统计学习就是计算机系统通过运用数据及统计方法提高系统性能的机器学习。



统计学习研究的对象是数据（data）。它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。



统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。由于它们具有统计规律性，所以可以用概率统计方法处理它们。



统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。



统计学习由监督学习（supervised learning）、无监督学习(unsupervised learning)和强化学习(reinforcement learning)等组成。



统计学习方法可以概括如下：从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间（hypothesis space）；应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优模型，使它对已知的训练数据及未知的测试数据（test data）在给定的评价准则下有最优的预测；最优模型的选取由算法实现。这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法。称其为统计学习方法的三要素，简称为模型（model）、策略（strategy）和算法（algorithm）。



实现统计学习方法的步骤如下：

1 得到一个有限的训练数据集合

2 确定包含所有可能的模型的假设空间，即学习模型的集合

3 确定模型选择的准则，即学习的策略

4 实现求解最优模型的算法，即学习的算法

5 通过学习方法选择最优模型

6 利用学习的最优模型对新数据进行预测或分析



统计学习研究一般包括统计学习方法、统计学习理论及统计学习应用三个方面。统计学习方法的研究旨在开发新的学习方法；统计学习理论的研究在于探求统计学习方法的有效性与效率，以及统计学习的基本理论问题；统计学习应用的研究主要考虑将统计学习方法应用到实际问题中去，解决实际问题。



## 统计学习的分类

1 监督学习（supervised learning）：从标注数据中学习预测模型的机器学习问题。

标注数据表示输入输出的对应关系，==监督学习的本质是学习输入到输出的映射的统计规律==。

（1）输入空间、特征空间和输出空间

在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间（input space）与输出空间（output space）。 输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。

每个具体的输入是一个实例（instance），通常由特征向量（feature vector）表示。这时，所有特征向量存在的空间称为特征空间（feature space）。特征空间的每一维对应于一个特征。有时建设输入空间与特征空间为相同的空间，对它们不予区分；有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。

在监督学习中，将输入与输出看作是定义在输入（特征）空间与输出空间上的随机变量的取值。



输入输出变量用大写字母表示，习惯上输入变量写作X，输出变量写作Y。

输入输出变量的取值用小写字母表示，输入变量的取值写作x，输出变量的取值写作y。

变量可以是标量或向量



输入实例x的特征向量记作：

![image-20230725095235304](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725095235304.png)

![image-20230725095308729](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725095308729.png)

监督学习从训练数据（training data）集合中学习模型，对测试数据（test data）进行预测。

训练数据由输入（或特征向量）与输出对组成，训练集通常表示为

![image-20230725095534654](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725095534654.png)

测试数据也由输入与输出对组成。输入与输出对又称为样本（sample）或样本点。



输入变量X和输出变量Y有不同的类型，可以是连续的，也可以是离散的。

输入变量与输出变量均为连续变量的预测问题称为==回归问题==

输出变量为有限个离散变量的预测问题称为==分类问题==

输入变量与输出变量均为变量序列的预测问题称为==标注问题==。



监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y).

P(X,Y)表示分布函数，或分布密度函数。注意在学习过程中，假定这一联合概率分布存在,但对学习系统来说,联合概率分布的具体定义是未知的.训练数据与测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的.统计学习假设数据存在一定的统计规律,==X和Y具有联合概率分布就是监督学习关于数据的基本假设==。



假设空间

监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到最好的这样的模型。模型属于输入空间到输出空间的映射的集合，这个集合就是假设空间（hypothesis space）。假设空间的确定意味着学习的范围的确定。



监督学习的模型可以是概率模型或非概率模型，由条件概率分布P(Y|X)或决策函数（decision function）Y=f(X)表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作P(y|x)或y=f(x)。



监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测。由于在这个过程中需要标注的训练数据集，而标注的训练数据集往往是人工给出的，所以称为监督学习。监督学习分为学习和预测两个过程，由学习系统与预测系统完成，可用下图描述。

![image-20230725103642756](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725103642756.png)



首先给定一个训练数据集

![image-20230725104428482](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104428482.png)

其中（xi,yi)，i=1,2,...,N,称为样本或样本点。![image-20230725104533895](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104533895.png)

是输入的观测值，也称为输入或实例，![image-20230725104733868](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104733868.png)

是输出的观测值，也称为输出。

​    监督学习分为学习和预测两个过程，由学习系统与预测系统完成。在学习过程中，学习系统利用给定的训练数据集，通过学习（或训练）得到一个模型，表示为条件概率分布

![image-20230725104911276](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104911276.png)

或决策函数![image-20230725104931423](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104931423.png)

条件概率分布会决策函数描述输入与输出随机变量之间的映射关系。

预测系统对于给定的测试样本集中的输入![image-20230725105059913](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725105059913.png)

由模型![image-20230725105120695](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725105120695.png)

或![image-20230725105142646](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725105142646.png)

给出相应的输出。

​    在监督学习中，假设训练数据与测试数据是依据联合概率分布P(X,Y)独立同分布产生的。

​    学习系统（也就是学习算法）试图通过训练数据集中的样本（xi,yi）带来的信息学习模型。

对输入xi，一个具体的模型可以产生一个输出f(xi)，而训练数据集中对应的输出是yi。如果这个模型有很好的预测能力，训练样本输出yi和模型输出f(xi)之间的差就应该足够小。

​    学习系统通过不断尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时对未知的测试数据集的预测也有尽可能好的推广。



2 无监督学习

无监督学习（unsupervised learning）是指从无标注数据中学习预测模型的机器学习问题。

无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。==无监督学习的本质是学习数据中的统计规律或潜在结构==

每一个输出是对输入的分析结果，由输入的类别、转换或概率表示。模型可以实现对数据的聚类、降维或概率估计。

假设X是输入空间，Z是隐式结构空间。要学习的模型可以表示为函数z=g(x)，条件概率分布P(z|x)，或者条件概率分布P(x|z)的形式，其中x∈X是输入，z∈Z是输出。包含所有可能的模型的集合称为假设空间。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。

无监督学习通常使用大量的无标注数据学习或训练，每一个样本是一个实例。
