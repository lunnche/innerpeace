# 统计学习方法



主要内容：

感知机

k近邻法

朴素贝叶斯法

决策树

逻辑斯谛回归

最大熵模型

支持向量机

提升方法

EM算法

隐马尔科夫模型

条件随机场

聚类方法

奇异值分解

主成分分析

潜在语义分析

概率潜在语义分析

马尔可夫链蒙特卡罗法

潜在狄利克雷分配

PageRank算法





不涉及：

深度学习

强化学习



# 第一章 统计学习及监督学习概论



# 1.1 统计学习 

统计学习（statistical learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也称为统计机器学习（statistical machine learning）



学习：如果一个系统能够通过执行某个过程改进它的性能，这就是学习。——赫尔伯特·西蒙（Herbert A. Simon）



统计学习就是计算机系统通过运用数据及统计方法提高系统性能的机器学习。



统计学习研究的对象是数据（data）。它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。



统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。由于它们具有统计规律性，所以可以用概率统计方法处理它们。



统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。



统计学习由监督学习（supervised learning）、无监督学习(unsupervised learning)和强化学习(reinforcement learning)等组成。



统计学习方法可以概括如下：从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间（hypothesis space）；应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优模型，使它对已知的训练数据及未知的测试数据（test data）在给定的评价准则下有最优的预测；最优模型的选取由算法实现。这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法。称其为统计学习方法的三要素，简称为模型（model）、策略（strategy）和算法（algorithm）。



实现统计学习方法的步骤如下：

1 得到一个有限的训练数据集合

2 确定包含所有可能的模型的假设空间，即学习模型的集合

3 确定模型选择的准则，即学习的策略

4 实现求解最优模型的算法，即学习的算法

5 通过学习方法选择最优模型

6 利用学习的最优模型对新数据进行预测或分析



统计学习研究一般包括统计学习方法、统计学习理论及统计学习应用三个方面。统计学习方法的研究旨在开发新的学习方法；统计学习理论的研究在于探求统计学习方法的有效性与效率，以及统计学习的基本理论问题；统计学习应用的研究主要考虑将统计学习方法应用到实际问题中去，解决实际问题。



## 1.2 统计学习的分类

1 监督学习（supervised learning）：从标注数据中学习预测模型的机器学习问题。

标注数据表示输入输出的对应关系，==监督学习的本质是学习输入到输出的映射的统计规律==。

（1）输入空间、特征空间和输出空间

在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间（input space）与输出空间（output space）。 输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。

每个具体的输入是一个实例（instance），通常由特征向量（feature vector）表示。这时，所有特征向量存在的空间称为特征空间（feature space）。特征空间的每一维对应于一个特征。有时建设输入空间与特征空间为相同的空间，对它们不予区分；有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。

在监督学习中，将输入与输出看作是定义在输入（特征）空间与输出空间上的随机变量的取值。



输入输出变量用大写字母表示，习惯上输入变量写作X，输出变量写作Y。

输入输出变量的取值用小写字母表示，输入变量的取值写作x，输出变量的取值写作y。

变量可以是标量或向量



输入实例x的特征向量记作：

![image-20230725095235304](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725095235304.png)

![image-20230725095308729](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725095308729.png)

监督学习从训练数据（training data）集合中学习模型，对测试数据（test data）进行预测。

训练数据由输入（或特征向量）与输出对组成，训练集通常表示为

![image-20230725095534654](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725095534654.png)

测试数据也由输入与输出对组成。输入与输出对又称为样本（sample）或样本点。



输入变量X和输出变量Y有不同的类型，可以是连续的，也可以是离散的。

输入变量与输出变量均为连续变量的预测问题称为==回归问题==

输出变量为有限个离散变量的预测问题称为==分类问题==

输入变量与输出变量均为变量序列的预测问题称为==标注问题==。



监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y).

P(X,Y)表示分布函数，或分布密度函数。注意在学习过程中，假定这一联合概率分布存在,但对学习系统来说,联合概率分布的具体定义是未知的.训练数据与测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的.统计学习假设数据存在一定的统计规律,==X和Y具有联合概率分布就是监督学习关于数据的基本假设==。



假设空间

监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到最好的这样的模型。模型属于输入空间到输出空间的映射的集合，这个集合就是假设空间（hypothesis space）。假设空间的确定意味着学习的范围的确定。



监督学习的模型可以是概率模型或非概率模型，由条件概率分布P(Y|X)或决策函数（decision function）Y=f(X)表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作P(y|x)或y=f(x)。



监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测。由于在这个过程中需要标注的训练数据集，而标注的训练数据集往往是人工给出的，所以称为监督学习。监督学习分为学习和预测两个过程，由学习系统与预测系统完成，可用下图描述。

![image-20230725103642756](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725103642756.png)



首先给定一个训练数据集

![image-20230725104428482](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104428482.png)

其中（xi,yi)，i=1,2,...,N,称为样本或样本点。![image-20230725104533895](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104533895.png)

是输入的观测值，也称为输入或实例，![image-20230725104733868](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104733868.png)

是输出的观测值，也称为输出。

​    监督学习分为学习和预测两个过程，由学习系统与预测系统完成。在学习过程中，学习系统利用给定的训练数据集，通过学习（或训练）得到一个模型，表示为条件概率分布

![image-20230725104911276](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104911276.png)

或决策函数![image-20230725104931423](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725104931423.png)

条件概率分布会决策函数描述输入与输出随机变量之间的映射关系。

预测系统对于给定的测试样本集中的输入![image-20230725105059913](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725105059913.png)

由模型![image-20230725105120695](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725105120695.png)

或![image-20230725105142646](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725105142646.png)

给出相应的输出。

​    在监督学习中，假设训练数据与测试数据是依据联合概率分布P(X,Y)独立同分布产生的。

​    学习系统（也就是学习算法）试图通过训练数据集中的样本（xi,yi）带来的信息学习模型。

对输入xi，一个具体的模型可以产生一个输出f(xi)，而训练数据集中对应的输出是yi。如果这个模型有很好的预测能力，训练样本输出yi和模型输出f(xi)之间的差就应该足够小。

​    学习系统通过不断尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时对未知的测试数据集的预测也有尽可能好的推广。



2 无监督学习

无监督学习（unsupervised learning）是指从无标注数据中学习预测模型的机器学习问题。

无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。==无监督学习的本质是学习数据中的统计规律或潜在结构==

每一个输出是对输入的分析结果，由输入的类别、转换或概率表示。模型可以实现对数据的聚类、降维或概率估计。

假设X是输入空间，Z是隐式结构空间。要学习的模型可以表示为函数z=g(x)，条件概率分布P(z|x)，或者条件概率分布P(x|z)的形式，其中x∈X是输入，z∈Z是输出。包含所有可能的模型的集合称为假设空间。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。

无监督学习通常使用大量的无标注数据学习或训练，每一个样本是一个实例。训练数据表示为

U={x1,x2,...,xN},其中，xi,i=1,2,...,N，是样本。

​    无监督学习可以用于对已有数据的分析，也可以用于对未来数据的预测。分析时使用学习得到的模型，即函数![image-20230725115439496](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115439496.png)

，条件概率分布![image-20230725115509563](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115509563.png)

，或者条件概率分布![image-20230725115534213](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115534213.png)

。预测时，和监督学习有类似的流程。由学习系统与预测系统完成，如下图。

![image-20230725115624626](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115624626.png)

在学习过程中，学习系统从训练数据集学习，得到一个最优模型，表示为函数

![image-20230725115732410](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115732410.png)

，条件概率分布![image-20230725115753498](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115753498.png)

或者条件概率分布![image-20230725115814322](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115814322.png)

在预测过程中，预测系统对于给定的输入![image-20230725115845128](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115845128.png)

，由模型![image-20230725115904516](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115904516.png)

或![image-20230725115921043](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115921043.png)

给出相应的输出![image-20230725115953116](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725115953116.png)

，进行聚类或降维，或者由模型![image-20230725120023968](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725120023968.png)

给出输入的概率

![image-20230725120049650](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725120049650.png)

，进行概率估计。

-----



3 强化学习

强化学习（reinforcement learning）是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。假设智能系统与环境的互动基于马尔可夫决策过程（Markov decision process），智能系统能观测到的是与环境互动得到的数据序列。强化学习的本质是学习最优的序贯决策。

智能系统与环境的互动如图所示。

![image-20230725133657228](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725133657228.png)

在每一步t，智能系统从环境中观测到一个状态（state）st与一个奖励（reward）rt，采取一个动作（action）at。环境根据智能系统选择的动作，决定下一步t+1的状态s<sub>t+1</sub>与奖励r<sub>t+1</sub>。要学习的策略表示为给定状态下采取的动作。智能系统的目标不是短期奖励的最大化，而是长期累积奖励的最大化。强化学习过程中，系统不断地试错（trial and error），以达到学习最优策略的目的。

强化学习的马尔科夫决策过程是状态、奖励、动作序列上的随机过程，由五元组<S,A,P,r,γ>组成。   γ 伽马

* S是有限状态（state）的集合
* A是有限动作（action）的集合
* P是状态转移概率（transiton probability）的函数

$\ P(s^{'}|s,a)=P(s_{t+1}=s^{'}|s_t=s,a_t=a)  $

* r是奖励函数（reward function）：

$\ r(s,a)=E(r_{t+1}|s_t=s,a_t=a) $

* $\ \gamma $ 是衰减系数（discount factor）: $\ \gamma \in [0,1]$

马尔科夫决策过程具有马尔科夫性，下一个状态只依赖于前一个状态与动作，由状态转义概率函数$ \ P(s^{'}|s,a)$ 表示。下一个奖励依赖于前一个状态与动作，由奖励函数r(s,a)表示。

策略π定义为给定状态下动作的函数a=f(s)或者条件概率分布P(a|s)。给定一个策略π，智能系统与环境互动的行为就已确定  （或者是确定性的或者是随机性的）。

​    价值函数（value function）或状态价值函数（state value function ）定义为策略π从某一个状态s开始的长期累积奖励的数学期望：
$$
q_\pi(s,a)=E_\pi[r_{t+1}+\gamma r_{t+2}+\gamma^2 r_{t+3}+\cdots|s_t=s,a_t=a]
$$
强化学习的目标就是在所有可能的策略中选出价值函数最大的策略$\ \pi^*$，而在实际学习中往往从具体的策略出发，不断优化已有策略。这里$\ \gamma$表示未来的奖励会有衰减。

​    强化学习方法中有基于策略（policy-based）、基于价值的（value-based），这两者属于无模型（model-free）的方法，还有有模型的（model-based）方法。

​    有模型的方法试图直接学习马尔科夫决策过程的模型，包括转移概率函数$\ P(s^{'}|s,a)$ 和奖励函数$\ r(s,a) $ 。这样可以通过模型对环境的反馈进行预测，求出价值函数最大的策略$\ \pi^*$ 

​    无模型的、基于策略的方法不直接学习模型，而是试图求解最优策略$\ \pi^*$ ，表示为函数a=f\*(s)或者是条件概率分布$\ P^*(a|s)$ ，这样也能达到在环境中做出最优决策的目的。学习通常从一个具体策略开始，通过搜索更优的策略进行。

​    无模型的、基于价值的方法也不直接学习模型，而是试图求解最优价值函数，特别是最优动作价值函数$\ q^*(s,a)$ 。这样可以简介地学到最优策略，根据该策略在给定的状态下做出相应的动作。学习通常从一个具体价值函数开始，通过搜过更优的价值函数进行。



---

4 半监督学习与主动学习

半监督学习（semi-supervised learning）是指利用标注数据和未标注数据学习预测模型的机器学习问题。通常有少量标注数据、大量未标注数据，因为标注数据的构建往往需要人工，成本较高，未标注数据的收集不需太多成本。半监督学习旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果。

主动学习（active learning）是指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据，往往是随机得到的，可以看作是“被动学习”，主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价，达到较好的学习效果。

​    半监督学习和主动学习更接近监督学习。



___

## 按模型分类

### 概率模型与非概率模型

概率模型（probabilistic model）和非概率模型（non-probabilistic model）或者确定性模型(deterministic model)。在监督学习中，概率模型取条件概率分布形势$\ P(y|x)$ ，非概率模型取函数形势$\ y=f(x)$ 。在无监督学习中，概率模型取条件概率分布$\ P(z|x)$ 或 $\ P(x|z) $ ，非概率模型取函数形式$\ z=g(x)$ 。



在监督学习中，概率模型是生成模型，非概率模型是判别模型。



决策树、朴素贝叶斯、隐马尔科夫模型、条件随机场、概率潜在语义分析、潜在狄利克雷分配、高斯混合模型是概率模型。

感知机、支持向量机、k近邻、AdaBoost、k均值、潜在语义分析、神经网络是非概率模型。

逻辑斯地回归既可看作是概率模型，又可看作非概率模型。



条件概率分布$\ P(y|x)$ 和函数$\ y=f(x) $ 可以相互转化。具体地，条件概率分布最大化后得到函数，函数归一化后得到条件概率分布。所以，概率模型和非概率模型的区别不在于输入与输出之间的映射关系，而在于模型的内在结构。概率模型一定可以表示为联合概率分布的形式，其中的变量表示输入、输出、隐变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。



概率模型的代表是概率图模型（probabilistic graphical model），概率图模型是联合概率分布由有向图后者无向图表示的概率模型，而联合概率分布可以根据图的结构分解为因子乘积的形式。贝叶斯网络、马尔科夫随机场、条件随机场是概率图模型。无论模型如何复杂，均可以用最基本的加法规则和乘法规则进行概率推理。

加法规则：$\ P(x)=\sum_y P(x,y)$

乘法规则：$\ P(x,y)=P(x)P(y|x)$

其中x和y是随机变量



### 线性模型和非线性模型

 统计学习模型，特别是非概率模型，可以分为线性模型(linear model)和非线性模型(non-linear model)。如果函数$\ y=f(x)$ 或 $\ z=g(x)$ 是线性函数，则称模型是线性模型，否则称模型是非线性模型。

​    感知机、线性支持向量机、k近邻、k均值、潜在语义分析是线性模型。核函数支持向量机、AdaBoost、神经网络是非线性模型。

深度学习（deep learning）实际是复杂神经网络的学习，也就是复杂的非线性模型的学习。



### 参数化模型与非参数化模型

参数化模型（parametric model）假设模型参数的维度固定，模型可以由有限维参数完全刻画。

非参数化模型(non-parametric model)假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加不断增大。

感知机、朴素贝叶斯、逻辑斯地回归、k均值、高斯混合模型是参数化模型。

决策树、支持向量机、AdaBoost、k近邻、潜在语义分析、概率潜在语义分析、潜在狄利克雷分配是非参数化模型。

参数化模型适合问题简单的情况，现实中问题往往比较复杂，非参数化模型更加有效。

---

## 按算法分类

在线学习（online learning）：每次接受一个样本，进行预测，之后学习模型，并不断重复该操作的机器学习。

批量学习（batch learning）：一次接受所有数据，学习模型，之后进行预测。



有些实际应用场景要求学习必须是在线的。比如，数据依次达到无法存储，系统需要及时做出处理。数据规模很大，不可能一次处理所有数据。数据的模式随时间动态变化，需要算法快速适应新的模式（不满足独立同分布假设）。

在线学习可以是监督学习，也可以是无监督学习，强化学习本身就拥有在线学习的特点。



在线监督学习：

学习和预测在一个系统，每次接受一个输入$\ x_t$ ，用已有模型给出预测 $\ \hat{f}(x_t)$ ，之后得到相应的反馈，即该输入对应的输出$\ y_t$ ,系统用损失函数计算两者的差异，更新模型；并不断重复以上操作。

![image-20230725161403368](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230725161403368.png)

利用随机梯度下降的感知机学习算法就是在线学习算法。



在线学习通常比批量学习更难，很难学到预测准确率更高的模型，因为每次模型更新中，可利用的数据有限。



## 按技巧分类

### 贝叶斯学习

贝叶斯学习（bayesian learning），又称为贝叶斯推理（Bayesian inference），其主要想法是，在概率模型的学习和推理中，利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率，并应用这个原理进行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，使用模型的先验分布是贝叶斯学习的特点。贝叶斯学习中也使用基本概率公式。

![image-20230726085516857](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230726085516857.png)

假设随机变量D表示数据，随机变量$\ \theta$ 表示模型参数。根据贝叶斯定理，可以用以下公式计算后验概率$\ P(\theta|D)$ ：
$$
P(\theta|D)=\frac{P(\theta)P(D|\theta)}{P(D)}
$$
其中$\ P(\theta) $ 是先验概率，$\ P(D|\theta)$ 是似然函数。

​    模型估计时，估计整个后验概率分布$\ P(\theta|D)$ 。如果需要给出一个模型，通常取后验概率最大的模型。

​    预测时，计算数据对后验概率分布的期望值：
$$
P(x|D)=\int{P(x|\theta,D)P(\theta|D)}d\theta
$$
这里x是新样本。

​    贝叶斯估计与极大似然估计在思想上有很大不同，代表着统计学中贝叶斯学派和频率学派对统计的不同认识。其实，可以简单地把两者联系起来，假设先验分布是均匀分布，取后验概率最大，就能从贝叶斯估计得到最大似然估计。

![image-20230726090635898](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230726090635898.png)

### 核方法

核方法（kernel method）是使用核函数表示和学习非线性模型的一种机器学习方法，可以用于监督学习和无监督学习。有一些线性模型的学习方法基于相似度计算，更具体地，向量内积计算。核方法可以把它们扩展到非线性模型的学习，使其应用范围更广泛。

把线性模型扩展到非线性模型，直接的做法是显式定义从输入空间（低维空间）到特征空间（高维空间）的映射，在特征空间中进行内积计算。比如，支持向量机，把输入空间的线性不可分问题转化为特征空间的线性可分问题，如图

![image-20230726091448501](https://raw.githubusercontent.com/lunnche/picgo-image/main/image-20230726091448501.png)

核方法的技巧在于不显式定义这个映射，而是直接定义核函数，即映射之后在特征空间的内积。这样可以简化计算，达到同样的效果。

​    假设$\ x_1$ 和 $\ x_2 $ 是输入空间的任意两个实例（向量），其内积是$\ <x_1,x_2>$ 。假设从输入空间到特征空间的映射是$\ \phi$ ，于是$\ x_1$ 和$\ x_2$ 在特征空间的映射是 $\ \phi(x_1)$ 和$\ \phi(x_2)$ ，其内积是$\ <\phi(x_1),\phi(x_2)>$ 。核方法直接在输入空间中定义核函数$\ K(x_1,x_2)$ ，使其满足$\ K(x_1,x_2)=<\phi(x_1),\phi(x_2)>$ 。表示定理给出核函数技巧成立的充要条件。



## 1.3 统计学习方法三要素

方法=模型+策略+算法



### 1.3.1 模型

在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间（hypothesis space） 包含所有可能的条件概率分布或决策函数。例如，假设决策函数是输入变量的线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合。假设空间中的模型一般有无穷多个。

​    假设空间用$\ F$ 表示。假设空间可以定义为决策函数的集合：
$$
F = \{f|Y = f(X)\}
$$
其中，X和Y是定义在输入空间X和输出空间Y上的变量。这时F通常是由一个参数向量决定的函数族：
$$
F = \{ f| Y = f_\theta(X),\theta \in R^n\}
$$
参数向量$\ \theta$ 取值于n维欧氏空间$\ R^n$ ，称为参数空间（parameter space）。

​    假设空间也可以定义为条件概率的集合：
$$
F = \{ P|P(Y|X)\}
$$
其中，X和Y是定义在输入空间X和输出空间Y上的随机变量。这时F通常是由一个参数向量决定的条件概率分布族：
$$
F = \{P|P_\theta(Y|X),\theta\in R^n\}
$$
参数向量$\ \theta$ 取值于n维欧氏空间$\ R^n$ ，也称为参数空间。



### 1.3 策略

有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。统计学习的目标在于从假设空间中选取最优模型。

​    首先引入损失函数与风险函数的概念。

​    损失函数度量模型一次预测的好坏。

​    风险函数度量平均意义下模型预测的好坏。



监督学习问题是在假设空间F中选取模型f作为决策函数，对于给定的输入X，由f(X)给出相应的输出Y，这个输出的预测值f(X)与真实值Y可能一致也可能不一致，用一个损失函数(loss function)或代价函数(cost function)来度量预测错误的程度。损失函数是f(X)和Y的非负实值函数，记作L(Y，f(X))。



统计学习常用的损失函数有以下几种：

（1） 0-1损失函数（0-1 loss function）
$$
L(Y,f(X)) = \left\{
\begin{aligned}
1, y \neq f(X)

\end{aligned}
\right\}
$$


